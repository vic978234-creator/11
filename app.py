import streamlit as st
import requests
import google.generativeai as genai
from datetime import datetime, timedelta

# ==========================================
# ğŸ‘‡ API í‚¤ ì„¤ì •
# ==========================================
GEMINI_API_KEY = "AIzaSyAeViQ5me2F19XOPv3VbzIq-nqB6Wwrggc"
KOBIS_API_KEY = "f6ae9fdbd8ba038eda177250d3e57b4c"
# ==========================================

st.set_page_config(page_title="ì˜í™” AI (ìë™ë³µêµ¬ëª¨ë“œ)", page_icon="ğŸš‘")

st.title("ğŸš‘ AI ì˜í™”ê´€ (ìë™ ëª¨ë¸ ê°ì§€)")
st.caption("ì˜¤ë¥˜ í•´ê²°ì„ ìœ„í•´ ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ì°¾ìŠµë‹ˆë‹¤.")

# --- 1. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì°¾ê¸° í•¨ìˆ˜ (í•µì‹¬) ---
def find_working_model(api_key):
    """API í‚¤ë¥¼ ì´ìš©í•´ í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì´ë¦„ì„ ì°¾ì•„ëƒ…ë‹ˆë‹¤."""
    try:
        genai.configure(api_key=api_key)
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
        available_models = []
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                available_models.append(m.name)
        
        # 1ìˆœìœ„: Flash (ë¹ ë¦„), 2ìˆœìœ„: Pro (ì•ˆì •ì ), 3ìˆœìœ„: ì•„ë¬´ê±°ë‚˜
        if 'models/gemini-1.5-flash' in available_models:
            return 'gemini-1.5-flash', available_models
        elif 'models/gemini-pro' in available_models:
            return 'gemini-pro', available_models
        elif len(available_models) > 0:
            # ëª¨ë¸ ì´ë¦„ ì•ì— 'models/'ê°€ ë¶™ì–´ìˆìœ¼ë©´ ë–¼ê³  ë°˜í™˜ ì‹œë„
            return available_models[0].replace('models/', ''), available_models
        else:
            return None, []
    except Exception as e:
        return None, str(e)

# --- 2. ë°•ìŠ¤ì˜¤í”¼ìŠ¤ ë°ì´í„° í•¨ìˆ˜ ---
def get_box_office_data(date):
    dt_str = date.strftime("%Y%m%d")
    url = f"http://www.kobis.or.kr/kobisopenapi/webservice/rest/boxoffice/searchDailyBoxOfficeList.json?key={KOBIS_API_KEY}&targetDt={dt_str}"
    try:
        response = requests.get(url)
        data = response.json()
        daily_list = data.get('boxOfficeResult', {}).get('dailyBoxOfficeList', [])
        if not daily_list: return "ë°ì´í„° ì—†ìŒ"
        text = ""
        for item in daily_list:
            text += f"[{item['rank']}ìœ„] {item['movieNm']} (ê´€ê°: {item['audiAcc']}ëª…)\n"
        return text
    except: return "í†µì‹  ì˜¤ë¥˜"

# --- 3. Gemini ëŒ€í™” í•¨ìˆ˜ ---
def ask_gemini(model_name, user_input, movie_data, role):
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel(model_name)
        
        prompt = f"ì—­í• : {role}\nì •ë³´: {movie_data}\nì§ˆë¬¸: {user_input}\nìœ„ ì •ë³´ë¡œ ëŒ€ë‹µí•´."
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"ì—ëŸ¬ ë°œìƒ: {e}"

# --- ë©”ì¸ ì‹¤í–‰ ë¡œì§ ---

# ì‚¬ì´ë“œë°”ì—ì„œ ëª¨ë¸ ìƒíƒœ ì§„ë‹¨
with st.sidebar:
    st.header("ğŸ› ï¸ ì‹œìŠ¤í…œ ì§„ë‹¨")
    
    # ëª¨ë¸ ì°¾ê¸° ì‹¤í–‰
    target_model, all_models = find_working_model(GEMINI_API_KEY)
    
    if target_model:
        st.success(f"ì—°ê²° ì„±ê³µ! \nì‚¬ìš© ëª¨ë¸: {target_model}")
        with st.expander("ì „ì²´ ëª¨ë¸ ëª©ë¡ ë³´ê¸°"):
            st.write(all_models)
    else:
        st.error("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.error(f"ì˜¤ë¥˜ ë‚´ìš©: {all_models}") # ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥
        st.warning("í„°ë¯¸ë„ì—ì„œ 'python -m pip install --upgrade google-generativeai'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

    st.divider()
    persona = st.selectbox("ë§íˆ¬ ì„ íƒ", ["ì¹œì ˆí•œ ì•Œë°”ìƒ", "í‰ë¡ ê°€", "ì„ ë¹„"])
    target_date = st.date_input("ë‚ ì§œ", datetime.now() - timedelta(days=1))

# ë©”ì¸ í™”ë©´
if 'data' not in st.session_state: st.session_state['data'] = ""

# ë°ì´í„° ë¡œë“œ
if st.button("ë°ì´í„° ê°€ì ¸ì˜¤ê¸°") or not st.session_state['data']:
    st.session_state['data'] = get_box_office_data(target_date)

# ì±„íŒ…ì°½
if "msgs" not in st.session_state: st.session_state.msgs = []
for msg in st.session_state.msgs:
    st.chat_message(msg["role"]).markdown(msg["content"])

if prompt := st.chat_input("ì§ˆë¬¸í•˜ì„¸ìš”"):
    st.session_state.msgs.append({"role": "user", "content": prompt})
    st.chat_message("user").markdown(prompt)
    
    with st.chat_message("assistant"):
        if not target_model:
            st.error("AI ëª¨ë¸ì„ ì°¾ì§€ ëª»í•´ ëŒ€ë‹µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì˜ ì˜¤ë¥˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        else:
            with st.spinner(f"({target_model} ëª¨ë¸ì´ ìƒê° ì¤‘...)"):
                res = ask_gemini(target_model, prompt, st.session_state['data'], persona)
                st.markdown(res)
                st.session_state.msgs.append({"role": "assistant", "content": res})
